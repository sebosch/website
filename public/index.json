[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m the Open Science Coordinator at the VU Amsterdam and a postdoctoral researcher at the Donders Institute for Brain, Cognition and Behaviour.\nAt the VU, I\u0026rsquo;m initiating and managing projects that promote open access, open data, open software and open education. I strive to make the scientific process more transparent and its pillars (research, education, communication, leadership) more fairly and evenly appreciated.\nAt the Donders Institute, I work with Prof dr. Marcel van Gerven and his Artificial Cognitive Systems group. In several research projects, I apply state-of-the art methods from artificial intelligence to study learning, perception and imagery. I completed my PhD in the group of Prof. dr. Christian Doeller, where I combined psychophysics, fMRI and multivariate analyses to investigate hippocampal memory retrieval.\nMy interests include open science initiatives, the neural mechanisms of cognition, artificial intelligence and data science.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1581885671,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://www.sanderbosch.com/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I\u0026rsquo;m the Open Science Coordinator at the VU Amsterdam and a postdoctoral researcher at the Donders Institute for Brain, Cognition and Behaviour.\nAt the VU, I\u0026rsquo;m initiating and managing projects that promote open access, open data, open software and open education. I strive to make the scientific process more transparent and its pillars (research, education, communication, leadership) more fairly and evenly appreciated.\nAt the Donders Institute, I work with Prof dr.","tags":null,"title":"Dr. Sander Bosch","type":"authors"},{"authors":null,"categories":null,"content":" Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1557579039,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://www.sanderbosch.com/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557579039,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"https://www.sanderbosch.com/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":" Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557579039,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"https://www.sanderbosch.com/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557579039,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"https://www.sanderbosch.com/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["SC Quax","__SE Bosch__","MV Peelen","MAJ van Gerven"],"categories":null,"content":"","date":1610406000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616411007,"objectID":"b7586cb636084b6506ed20d5252570ba","permalink":"https://www.sanderbosch.com/publication/2021_quax_scirep/","publishdate":"2021-01-12T00:00:00+01:00","relpermalink":"/publication/2021_quax_scirep/","section":"publication","summary":"How the brain makes correct inferences about its environment based on noisy and ambiguous observations is one of the fundamental questions in Neuroscience. Prior knowledge about the probability with which certain events occur in the environment plays an important role in this process. Humans are able to incorporate such prior knowledge in an efficient, Bayes optimal, way in many situations, but it remains an open question how the brain acquires and represents this prior knowledge. The long time spans over which prior knowledge is acquired make it a challenging question to investigate experimentally. In order to guide future experiments with clear empirical predictions, we used a neural network model to learn two commonly used tasks in the experimental literature (i.e. orientation classification and orientation estimation) where the prior probability of observing a certain stimulus is manipulated. We show that a population of neurons learns to correctly represent and incorporate prior knowledge, by only receiving feedback about the accuracy of their inference from trial-to-trial and without any probabilistic feedback. We identify different factors that can influence the neural responses to unexpected or expected stimuli, and find a novel mechanism that changes the activation threshold of neurons, depending on the prior probability of the encoded stimulus. In a task where estimating the exact stimulus value is important, more likely stimuli also led to denser tuning curve distributions and narrower tuning curves, allocating computational resources such that information processing is enhanced for more likely stimuli. These results can explain several different experimental findings, clarify why some contradicting observations concerning the neural responses to expected versus unexpected stimuli have been reported and pose some clear and testable predictions about the neural representation of prior knowledge that can guide future experiments.","tags":["behavioural modelling","artificial neural networks","multivariate pattern analysis"],"title":"Population codes of prior knowledge learned through environmental regularities","type":"publication"},{"authors":["T Dado","Y Güçlütürk","L Ambrogioni","G Ras","__SE Bosch__","MAJ van Gerven","U Güçlü"],"categories":null,"content":"","date":1593554400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596622383,"objectID":"c54e99f710c3f4683a080928c54e648f","permalink":"https://www.sanderbosch.com/publication/2020_dado_biorxiv/","publishdate":"2020-07-01T00:00:00+02:00","relpermalink":"/publication/2020_dado_biorxiv/","section":"publication","summary":"We introduce a new framework for hyperrealistic reconstruction of perceived naturalistic stimuli from brain recordings. To this end, we embrace the use of generative adversarial networks (GANs) at the earliest step of our neural decoding pipeline by acquiring functional magnetic resonance imaging data as subjects perceived face images created by the generator network of a GAN. Subsequently, we used a linear decoding approach to predict the latent state of the GAN from brain data. Hence, latent representations that are needed for stimulus (re-)generation are obtained, leading to ground-breaking image reconstructions. Altogether, we have developed a highly promising approach for decoding neural representations of real-world data, which may pave the way for systematically analyzing neural information processing in the functional brain.","tags":["fMRI","face perception","artificial neural networks","reconstruction"],"title":"Hyperrealistic neural decoding: Linear reconstruction of face stimuli from fMRI measurements via the GAN latent space","type":"publication"},{"authors":["J Thielen","__SE Bosch__","TM van Leeuwen","MAJ van Gerven","R van Lier"],"categories":null,"content":"","date":1574636400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575022158,"objectID":"cf2f4eff52978fcc54bafa16684c0fe8","permalink":"https://www.sanderbosch.com/publication/2019_thielen_scirep/","publishdate":"2019-11-25T00:00:00+01:00","relpermalink":"/publication/2019_thielen_scirep/","section":"publication","summary":"Eye movements can have serious confounding effects in cognitive neuroscience experiments. Therefore, participants are commonly asked to fixate. Regardless, participants will make so-called fixational eye movements under attempted fixation, which are thought to be necessary to prevent perceptual fading. Neural changes related to these eye movements could potentially explain previously reported neural decoding and neuroimaging results under attempted fixation. In previous work, under attempted fixation and passive viewing, we found no evidence for systematic eye movements. Here, however, we show that participants’ eye movements are systematic under attempted fixation when active viewing is demanded by the task. Since eye movements directly affect early visual cortex activity, commonly used for neural decoding, our findings imply alternative explanations for previously reported results in neural decoding.","tags":["behavioural modelling","eye movements","visual perception","psychophysics","multivariate pattern analysis"],"title":"Evidence for confounding eye movements under attempted fixation and active viewing in cognitive neuroscience","type":"publication"},{"authors":["N Dijkstra","M Hinne","__SE Bosch__","MAJ van Gerven"],"categories":null,"content":"","date":1573081200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573595013,"objectID":"25c624e0e620851d3984bb0a2c3b3b8c","permalink":"https://www.sanderbosch.com/publication/2019_dijkstra_scirep/","publishdate":"2019-11-07T00:00:00+01:00","relpermalink":"/publication/2019_dijkstra_scirep/","section":"publication","summary":"Mental imagery and visual perception rely on similar neural mechanisms, but the function of this overlap remains unclear. One idea is that imagery can influence perception. Previous research has shown that imagining a stimulus prior to binocular presentation of rivalling stimuli increases the chance of perceiving the imagined stimulus. In this study we investigated how this effect interacts with bottom-up sensory input by comparing psychometric response curves for congruent and incongruent imagery in humans. A Bayesian hierarchical model was used, allowing us to simultaneously study group-level effects as well as effects for individual participants. We found strong effects of both imagery as well as its interaction with sensory evidence within individual participants. However, the direction of these effects were highly variable between individuals, leading to weak effects at the group level. This highlights the heterogeneity of conscious perception and emphasizes the need for individualized investigation of such complex cognitive processes.","tags":["behavioural modelling","mental imagery","visual perception","psychophysics","binocular rivalry","bayesian model"],"title":"Between-subject variability in the influence of mental imagery on conscious perception","type":"publication"},{"authors":["J Thielen","U Güçlü","Y Güçlütürk","L Ambrogioni","__SE Bosch__","MAJ van Gerven"],"categories":null,"content":"","date":1565733600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566293621,"objectID":"6a2fb7905558a767fc405050ce6672dc","permalink":"https://www.sanderbosch.com/publication/2019_thielen_biorxiv/","publishdate":"2019-08-14T00:00:00+02:00","relpermalink":"/publication/2019_thielen_biorxiv/","section":"publication","summary":"Population receptive field (pRF) mapping is an important asset for cognitive neuroscience. The pRF model is used for estimating retinotopy, defining functional localizers and to study a vast amount of cognitive tasks. In a classic pRF, the cartesian location and receptive field size are modeled as a 2D Gaussian kernel in visual space and are estimated by optimizing the fit between observed responses and predicted responses. In the standard framework this is achieved using an iterative gradient descent algorithm. This optimization is time consuming because the number of pRFs to fit (e.g., fMRI voxels) is typically large. This computation time increases further with the complexity of the pRF model (e.g., adding HRF parameters, surround suppression and uncertainty measures). Here, we introduce DeepRF, which uses deep convolutional neural networks to estimate pRFs. We compare the performance of DeepRF with that of the conventional method using a synthetic dataset for which the ground truth is known and an empirical dataset. We show that DeepRF achieves state-of-the-art performance while being more than 3 orders of magnitude faster than the conventional method. This enables easier and faster modeling of more complex pRF models, resolving an important limitation of the conventional approach.","tags":["fMRI","visual perception","population receptive field mapping","artificial neural networks"],"title":"DeepRF: Ultrafast population receptive field mapping with deep learning","type":"publication"},{"authors":["K Seeliger","RP Sommers","U Güçlü","__SE Bosch__","MAJ van Gerven"],"categories":null,"content":"","date":1563573600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564657623,"objectID":"0a57f83bf43465db7e3b35641380d3d9","permalink":"https://www.sanderbosch.com/publication/2019_seeliger_biorxiv/","publishdate":"2019-07-20T00:00:00+02:00","relpermalink":"/publication/2019_seeliger_biorxiv/","section":"publication","summary":"Visual and auditory representations in the human brain have been studied with encoding, decoding and reconstruction models. Representations from convolutional neural networks have been used as explanatory models for these stimulus-induced hierarchical brain activations. However, none of the fMRI datasets currently available has adequate amounts of data for sufficiently sampling their representations. We recorded a densely sampled large fMRI dataset (TR=700 ms) in a single individual exposed to spatiotemporal visual and auditory naturalistic stimuli (30 episodes of BBC’s Doctor Who). The data consists of 120.830 whole-brain volumes (approx. 23 h) of single-presentation data (full episodes, training set) and 1.178 volumes (11 min) of repeated narrative short episodes (test set, 22 repetitions), recorded with fixation over a period of six months. This rich dataset can be used widely to study the way the brain represents audiovisual input across its sensory hierarchies.","tags":["fMRI","visual perception","naturalistic stimuli","artificial neural networks","multivariate pattern analysis"],"title":"A large single-participant fMRI dataset for probing brain responses to naturalistic stimuli in space and time","type":"publication"},{"authors":["SC Quax","N Dijkstra","MJ van Staveren","__SE Bosch__","MAJ van Gerven"],"categories":null,"content":"","date":1556661600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557579039,"objectID":"4dc8df3e5680fc98832871b950046d03","permalink":"https://www.sanderbosch.com/publication/2019_quax_neuroimage/","publishdate":"2019-05-01T00:00:00+02:00","relpermalink":"/publication/2019_quax_neuroimage/","section":"publication","summary":"Eye movements are an integral part of human perception, but can induce artifacts in many magnetoencephalography (MEG) and electroencephalography (EEG) studies. For this reason, investigators try to minimize eye movements and remove these artifacts from their data using different techniques. When these artifacts are not purely random, but consistent regarding certain stimuli or conditions, the possibility arises that eye movements are actually inducing effects in the MEG signal. It remains unclear how much of an influence eye movements can have on observed effects in MEG, since most MEG studies lack a control analysis to verify whether an effect found in the MEG signal is induced by eye movements. Here, we find that we can decode stimulus location from eye movements in two different stages of a working memory match-to-sample task that encompass different areas of research typically done with MEG. This means that the observed MEG effect might be (partly) due to eye movements instead of any true neural correlate. We suggest how to check for eye movement effects in the data and make suggestions on how to minimize eye movement artifacts from occurring in the first place.","tags":["MEG","working memory","eye movements","multivariate pattern analysis"],"title":"Eye movements explain decodability during perception and cued attention in MEG","type":"publication"},{"authors":["J Thielen","__SE Bosch__","TM van Leeuwen","MAJ van Gerven","R van Lier"],"categories":null,"content":"","date":1554069600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556980323,"objectID":"0a62bfea4229aed2b4be08e9aa0a45d9","permalink":"https://www.sanderbosch.com/publication/2019_thielen_iperception/","publishdate":"2019-04-01T00:00:00+02:00","relpermalink":"/publication/2019_thielen_iperception/","section":"publication","summary":"Amodal completion is the phenomenon of perceiving completed objects even though physically they are partially occluded. In this review, we provide an extensive overview of the results obtained from a variety of neuroimaging studies on the neural correlates of amodal completion. We discuss whether low-level and high-level cortical areas are implicated in amodal completion; provide an overview of how amodal completion unfolds over time while dissociating feedforward, recurrent, and feedback processes; and discuss how amodal completion is represented at the neuronal level. The involvement of low-level visual areas such as V1 and V2 is not yet clear, while several high-level structures such as the lateral occipital complex and fusiform face area seem invariant to occlusion of objects and faces, respectively, and several motor areas seem to code for object permanence. The variety of results on the timing of amodal completion hints to a mixture of feedforward, recurrent, and feedback processes. We discuss whether the invisible parts of the occluded object are represented as if they were visible, contrary to a high-level representation. While plenty of questions on amodal completion remain, this review presents an overview of the neuroimaging findings reported to date, summarizes several insights from computational models, and connects research of other perceptual completion processes such as modal completion. In all, it is suggested that amodal completion is the solution to deal with various types of incomplete retinal information, and highly depends on stimulus complexity and saliency, and therefore also give rise to a variety of observed neural patterns.","tags":["review","visual perception","amodal completion"],"title":"Neuroimaging findings on amodal completion: a review","type":"publication"},{"authors":["N Dijkstra","__SE Bosch__","MAJ van Gerven"],"categories":null,"content":"","date":1551394800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556980323,"objectID":"9d95c47c4f8a156641222bfe217ca227","permalink":"https://www.sanderbosch.com/publication/2019_dijkstra_tics/","publishdate":"2019-03-01T00:00:00+01:00","relpermalink":"/publication/2019_dijkstra_tics/","section":"publication","summary":"For decades, the extent to which visual imagery relies on the same neural mechanisms as visual perception has been a topic of debate. Here, we review recent neuroimaging studies comparing these two forms of visual experience. Their results suggest that there is a large overlap in neural processing during perception and imagery: neural representations of imagined and perceived stimuli are similar in the visual, parietal, and frontal cortex. Furthermore, perception and imagery seem to rely on similar top-down connectivity. The most prominent difference is the absence of bottom-up processing during imagery. These findings fit well with the idea that imagery and perception rely on similar emulation or prediction processes.","tags":["review","mental imagery","visual perception"],"title":"Shared neural mechanisms of visual perception and imagery","type":"publication"},{"authors":["Dr. Sander Bosch"],"categories":[],"content":" from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')  print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and Jupyter Install Anaconda which includes Python 3 and Jupyter notebook.\nOtherwise, for advanced users, install Jupyter notebook with pip3 install jupyter.\nCreate a new blog post as usual Run the following commands in your Terminal, substituting \u0026lt;MY_WEBSITE_FOLDER\u0026gt; and my-post with the file path to your Academic website folder and a name for your blog post (without spaces), respectively:\ncd \u0026lt;MY_WEBSITE_FOLDER\u0026gt; hugo new --kind post post/my-post cd \u0026lt;MY_WEBSITE_FOLDER\u0026gt;/content/post/my-post/  Create or upload a Jupyter notebook Run the following command to start Jupyter within your new blog post folder. Then create a new Jupyter notebook (New \u0026gt; Python Notebook) or upload a notebook.\njupyter notebook  Convert notebook to Markdown jupyter nbconvert Untitled.ipynb --to markdown --NbConvertApp.output_files_dir=. # Copy the contents of Untitled.md and append it to index.md: cat Untitled.md | tee -a index.md # Remove the temporary file: rm Untitled.md  Edit your post metadata Open index.md in your text editor and edit the title etc. in the front matter according to your preference.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557579039,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"https://www.sanderbosch.com/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557579039,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://www.sanderbosch.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557579039,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://www.sanderbosch.com/contact/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"Contact","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557579039,"objectID":"6087c0ef875554f4409ac52928d79279","permalink":"https://www.sanderbosch.com/projects/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/projects/","section":"","summary":"","tags":null,"title":"Projects","type":"widget_page"},{"authors":["K Seeliger","M Fritsche","U Güçlü","S Schoenmakers","J-M Schoffelen","__SE Bosch__","MAJ van Gerven"],"categories":null,"content":"","date":1538344800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556889476,"objectID":"e12f251e207f64cc80ddc6ead2949bff","permalink":"https://www.sanderbosch.com/publication/2018_seeliger_neuroimage/","publishdate":"2018-10-01T00:00:00+02:00","relpermalink":"/publication/2018_seeliger_neuroimage/","section":"publication","summary":"Representations learned by deep convolutional neural networks (CNNs) for object recognition are a widely investigated model of the processing hierarchy in the human visual system. Using functional magnetic resonance imaging, CNN representations of visual stimuli have previously been shown to correspond to processing stages in the ventral and dorsal streams of the visual system. Whether this correspondence between models and brain signals also holds for activity acquired at high temporal resolution has been explored less exhaustively. Here, we addressed this question by combining CNN-based encoding models with magnetoencephalography (MEG). Human participants passively viewed 1,000 images of objects while MEG signals were acquired. We modelled their high temporal resolution source-reconstructed cortical activity with CNNs, and observed a feed-forward sweep across the visual hierarchy between 75 and 200 ms after stimulus onset. This spatiotemporal cascade was captured by the network layer representations, where the increasingly abstract stimulus representation in the hierarchical network model was reflected in different parts of the visual cortex, following the visual ventral stream. We further validated the accuracy of our encoding model by decoding stimulus identity in a left-out validation set of viewed objects, achieving state-of-the-art decoding accuracy.","tags":["MEG","artificial neural networks","visual perception","object recognition","multivariate pattern analysis","encoding"],"title":"Convolutional neural network-based encoding and decoding of visual object recognition in space and time","type":"publication"},{"authors":["N Dijkstra","P Mostert","FP de Lange","__SE Bosch__","MAJ van Gerven"],"categories":null,"content":"","date":1527544800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557579039,"objectID":"1ed45c9319acb83631251e7e69ee9283","permalink":"https://www.sanderbosch.com/publication/2018_dijkstra_elife/","publishdate":"2018-05-29T00:00:00+02:00","relpermalink":"/publication/2018_dijkstra_elife/","section":"publication","summary":"Visual perception and imagery rely on similar representations in the visual cortex. During perception, visual activity is characterized by distinct processing stages, but the temporal dynamics underlying imagery remain unclear. Here, we investigated the dynamics of visual imagery in human participants using magnetoencephalography. Firstly, we show that, compared to perception, imagery decoding becomes significant later and representations at the start of imagery already overlap with later time points. This suggests that during imagery, the entire visual representation is activated at once or that there are large differences in the timing of imagery between trials. Secondly, we found consistent overlap between imagery and perceptual processing around 160 ms and from 300 ms after stimulus onset. This indicates that the N170 gets reactivated during imagery and that imagery does not rely on early perceptual representations. Together, these results provide important insights for our understanding of the neural mechanisms of visual imagery.","tags":["MEG","mental imagery","visual perception","multivariate pattern analysis"],"title":"Differential temporal dynamics during visual imagery and perception","type":"publication"},{"authors":["Y Güçlütürk","U Güçlü","K Seeliger","__SE Bosch__","R van Lier","MAJ van Gerven"],"categories":null,"content":"","date":1506808800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607547911,"objectID":"8b34f1d89ddcd9822a2cdbd98d1d1f24","permalink":"https://www.sanderbosch.com/publication/2017_gucluturk_nips/","publishdate":"2017-10-01T00:00:00+02:00","relpermalink":"/publication/2017_gucluturk_nips/","section":"publication","summary":"Here, we present a novel approach to solve the problem of reconstructing perceived stimuli from brain responses by combining probabilistic inference with deep learning. Our approach first inverts the linear transformation from latent features to brain responses with maximum a posteriori estimation and then inverts the nonlinear transformation from perceived stimuli to latent features with adversarial training of convolutional neural networks. We test our approach with a functional magnetic resonance imaging experiment and show that it can generate state-of-the-art reconstructions of perceived faces from brain activations.","tags":["fMRI","face perception","artificial neural networks","reconstruction"],"title":"Reconstructing perceived faces from brain activations with deep adversarial neural decoding","type":"publication"},{"authors":["N Dijkstra","__SE Bosch__","MAJ van Gerven"],"categories":null,"content":"","date":1485903600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557579039,"objectID":"10accc2326dc1c4c6f4fc5fb22aae6ef","permalink":"https://www.sanderbosch.com/publication/2017_dijkstra_jon/","publishdate":"2017-02-01T00:00:00+01:00","relpermalink":"/publication/2017_dijkstra_jon/","section":"publication","summary":"Research into the neural correlates of individual differences in imagery vividness point to an important role of the early visual cortex. However, there is also great fluctuation of vividness within individuals, such that only looking at differences between people necessarily obscures the picture. In this study, we show that variation in moment-to-moment experienced vividness of visual imagery, within human subjects, depends on the activity of a large network of brain areas, including frontal, parietal, and visual areas. Furthermore, using a novel multivariate analysis technique, we show that the neural overlap between imagery and perception in the entire visual system correlates with experienced imagery vividness. This shows that the neural basis of imagery vividness is much more complicated than studies of individual differences seemed to suggest.","tags":["fMRI","mental imagery","visual perception","multivariate pattern analysis"],"title":"Vividness of visual imagery depends on the neural overlap with perception in visual areas","type":"publication"},{"authors":["__SE Bosch__","K Seeliger","MAJ van Gerven"],"categories":null,"content":"","date":1477692000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556980323,"objectID":"5b88788a38cd84ca9195eb6e33c6e8a9","permalink":"https://www.sanderbosch.com/publication/2016_bosch_biorxiv/","publishdate":"2016-10-29T00:00:00+02:00","relpermalink":"/publication/2016_bosch_biorxiv/","section":"publication","summary":"Artificial neural networks (ANNs) have seen renewed interest in the fields of computer science, artificial intelligence and neuroscience. Recent advances in improving the performance of ANNs open up an exciting new avenue for cognitive neuroscience research. Here, we propose that ANNs that learn to solve complex tasks based on reinforcement learning, can serve as a universal computational framework for analyzing the neural and behavioural correlates of cognitive processing. We demonstrate this idea on a challenging probabilistic categorization task, where neural network dynamics are linked to human behavioural and neural data as identical tasks are solved.","tags":["behavioural modelling","artificial neural networks","probabilistic learning"],"title":"Modeling cognitive processes with neural reinforcement learning","type":"publication"},{"authors":["AR Backus*","__SE Bosch__*","M Ekman","A Vicente Grabovetsky","CF Doeller (* denotes equal contributions)"],"categories":null,"content":"","date":1464732000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556910307,"objectID":"cc6233b9f78d7f5400a37a5807c6283f","permalink":"https://www.sanderbosch.com/publication/2016_backus_natcom/","publishdate":"2016-06-01T00:00:00+02:00","relpermalink":"/publication/2016_backus_natcom/","section":"publication","summary":"The ability to form associations between a multitude of events is the hallmark of episodic memory. Computational models have espoused the importance of the hippocampus as convergence zone, binding different aspects of an episode into a coherent representation, by integrating information from multiple brain regions. However, evidence for this long-held hypothesis is limited, since previous work has largely focused on representational and network properties of the hippocampus in isolation. Here we identify the hippocampus as mnemonic convergence zone, using a combination of multivariate pattern and graph-theoretical network analyses of functional magnetic resonance imaging data from humans performing an associative memory task. We observe overlap of conjunctive coding and hub-like network attributes in the hippocampus. These results provide evidence for mnemonic convergence in the hippocampus, underlying the integration of distributed information into episodic memory representations.","tags":["fMRI","episodic memory retrieval","hippocampus","representational similarity analysis","graph analysis"],"title":"Mnemonic convergence in the human hippocampus","type":"publication"},{"authors":null,"categories":null,"content":"Eye movements are crucial in our everyday lives: they allow us to quickly browse the visual field for information without having to turn our heads every time. Eye movements are quick and can be triggered both internally (e.g. voluntary search like in Where\u0026rsquo;s Waldo) and externally (e.g. attentional capture by a flash of light).\nI was involved in a number of studies on the role of eye movements in cognition. In a study using fMRI-guided transcranial magnetic stimulation (TMS), we showed that single-pulse magnetic stimulation over a brain region called the Frontal Eye Field (FEF) could facilitate eye movements to the contralateral visual field in an oculomotor capture task. In other words, TMS over the FEF caused the eye movements to be faster and more accurate towards targets in the part of the visual field for which the FEF was responsible.\nFind more information on this project here.\nIn another study, we investigated whether measured neural effects (from magnetoencephalography or MEG)in a working memory task could be explained by systematic eye movements. Commonly, MEG researchers attempt to explain eye movements away by regressing out data from an electro-oculogram (EOG). We showed that this procedure is not sufficient to exclude the possibility that eye movements can (partly) explain the observed neural effects.\nFind more information on this project here.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607547911,"objectID":"250dc5c8a6a9c057a0ceaff0024f2a63","permalink":"https://www.sanderbosch.com/project/eye-movements/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/eye-movements/","section":"project","summary":"Eye movements are crucial in our everyday lives: they allow us to quickly browse the visual field for information without having to turn our heads every time. Eye movements are quick and can be triggered both internally (e.g. voluntary search like in Where\u0026rsquo;s Waldo) and externally (e.g. attentional capture by a flash of light).\nI was involved in a number of studies on the role of eye movements in cognition. In a study using fMRI-guided transcranial magnetic stimulation (TMS), we showed that single-pulse magnetic stimulation over a brain region called the Frontal Eye Field (FEF) could facilitate eye movements to the contralateral visual field in an oculomotor capture task.","tags":["research"],"title":"Eye movements","type":"project"},{"authors":null,"categories":null,"content":"During my PhD, I designed and executed a number of studies on memory retrieval. You can find my dissertation here.\nIn a collaboration with dr. Janneke Jehee\u0026rsquo;s Visual Computation group, we combined a task from visual psychophysics with fMRI and multivariate pattern analysis. We investigated whether memory retrieval of a visual stimulus would elicit activity patterns in early visual cortex, as predicted by the cortical reinstatement theory. We found that we could indeed classify the identity of the retrieved stimulus from cortical brain activity, and that the accuracy of retrieval correlated with activity in hippocampus. Find more information on this project here.\nIn a joint project with dr. Alexander Backus, we investigated the widely held view that the hippocampus acts as a convergence zone for mnemonic information. Convergence zones have several defining characteristics: they are well-connected and represent relevant information for memory. Participants learned associations between stimulus pairs, and performed a memory retrieval task in the fMRI scanner. We found that during retrieval, the hippocampus indeed 1) contains information about the retrieved stimulus category (through representational similarity analysis) and 2) is highly connected (through graph theoretical analysis). Find more information on this project here.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607547911,"objectID":"519c8b60cdfec4d5710ed99d2230a89e","permalink":"https://www.sanderbosch.com/project/memory-retrieval/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/memory-retrieval/","section":"project","summary":"During my PhD, I designed and executed a number of studies on memory retrieval. You can find my dissertation here.\nIn a collaboration with dr. Janneke Jehee\u0026rsquo;s Visual Computation group, we combined a task from visual psychophysics with fMRI and multivariate pattern analysis. We investigated whether memory retrieval of a visual stimulus would elicit activity patterns in early visual cortex, as predicted by the cortical reinstatement theory. We found that we could indeed classify the identity of the retrieved stimulus from cortical brain activity, and that the accuracy of retrieval correlated with activity in hippocampus.","tags":["research"],"title":"Memory retrieval","type":"project"},{"authors":null,"categories":null,"content":"This is work in progress\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607609191,"objectID":"5350b52b645941df3e458e2119d79ab5","permalink":"https://www.sanderbosch.com/project/mental-imagery/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/mental-imagery/","section":"project","summary":"This is work in progress","tags":["research"],"title":"Mental Imagery","type":"project"},{"authors":null,"categories":null,"content":"This is work in progress\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611750862,"objectID":"505583b2371f2a63507bb831a9d4a60b","permalink":"https://www.sanderbosch.com/project/open-science/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/open-science/","section":"project","summary":"This is work in progress","tags":["open science"],"title":"Open Science","type":"project"},{"authors":null,"categories":null,"content":"This is work in progress\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607609191,"objectID":"b80e3f4d8df50748749bef3b4df55620","permalink":"https://www.sanderbosch.com/project/research-data-management/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/research-data-management/","section":"project","summary":"This is work in progress","tags":["open science"],"title":"Research Data Management","type":"project"},{"authors":null,"categories":null,"content":"This is work in progress\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607609191,"objectID":"76b075b3acf914bb325990f00bd00870","permalink":"https://www.sanderbosch.com/project/research-intelligence/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/research-intelligence/","section":"project","summary":"This is work in progress","tags":["open science"],"title":"Research Intelligence","type":"project"},{"authors":["Dr. Sander Bosch"],"categories":[],"content":" Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 widgets, themes, and language packs included!\nCheck out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\n Setup Academic Get Started View the documentation Ask a question Request a feature or report a bug Updating? View the Update Guide and Release Notes Support development of Academic:  Donate a coffee Become a backer on Patreon Decorate your laptop or journal with an Academic sticker Wear the T-shirt   \nKey features:\n Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 15+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Color Themes Academic comes with day (light) and night (dark) mode built-in. Click the sun/moon icon in the top right of the Demo to see it in action!\nChoose a stunning color and font theme for your site. Themes are fully customizable and include:\n         Ecosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Then personalize and deploy your new site.\nUpdating View the Update Guide.\nFeel free to star the project on Github to help keep track of updates.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557579039,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://www.sanderbosch.com/post/getting-started/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website in under 10 minutes.","tags":["Academic"],"title":"Academic: the website builder for Hugo","type":"post"},{"authors":["__SE Bosch__"],"categories":null,"content":"","date":1459461600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556980323,"objectID":"8079a9000a47316ebe34786ed1d8a2f3","permalink":"https://www.sanderbosch.com/publication/2016_bosch_thesis/","publishdate":"2016-04-01T00:00:00+02:00","relpermalink":"/publication/2016_bosch_thesis/","section":"publication","summary":"_The Time Traveller: “Well, I do not mind telling you I have been at work upon this geometry of Four Dimensions for some time. Some of my results are curious. For instance, here is a portrait of a man at eight years old, another at fifteen, another at seventeen, another at twenty-three, and so on. All these are evidently sections, as it were, Three-Dimensional representations of his four-Dimensioned being, which is a fixed and unalterable thing (…)\nThe Medical Man: ’But (…) if Time is really only a fourth dimension of Space, why is it, and why has it always been, regarded as something different? And why cannot we move in Time as we move about in the other dimensions of Space? (…) you cannot move at all in Time, you cannot get away from the present moment.”\nThe Time Traveller: “(…) you are wrong to say that we cannot move about in Time. For instance, if I am recalling an incident very vividly I go back to the instant of its occurrence: I become absent-minded, as you say. I jump back for a moment.”_\nThe Time Machine, H.G. Wells, pp. 33-37","tags":["dissertation","memory retrieval","neocortex","hippocampus","fMRI"],"title":"Reactivating memories in hippocampus and neocortex","type":"publication"},{"authors":["__SE Bosch__","JFM Jehee","Guillén Fernández","CF Doeller"],"categories":null,"content":"","date":1398895200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558629141,"objectID":"3c325985d4477e6147ef410ff9f1472d","permalink":"https://www.sanderbosch.com/publication/2014_bosch_jon/","publishdate":"2014-05-01T00:00:00+02:00","relpermalink":"/publication/2014_bosch_jon/","section":"publication","summary":"The cortical reinstatement hypothesis of memory retrieval posits that content-specific cortical activity at encoding is reinstated at retrieval. Evidence for cortical reinstatement was found in higher-order sensory regions, reflecting reactivation of complex object-based information. However, it remains unclear whether the same detailed sensory, feature-based information perceived during encoding is subsequently reinstated in early sensory cortex and what the role of the hippocampus is in this process. In this study, we used a combination of visual psychophysics, functional neuroimaging, multivoxel pattern analysis, and a well controlled cued recall paradigm to address this issue. We found that the visual information human participants were retrieving could be predicted by the activation patterns in early visual cortex. Importantly, this reinstatement resembled the neural pattern elicited when participants viewed the visual stimuli passively, indicating shared representations between stimulus-driven activity and memory. Furthermore, hippocampal activity covaried with the strength of stimulus-specific cortical reinstatement on a trial-by-trial level during cued recall. These findings provide evidence for reinstatement of unique associative memories in early visual cortex and suggest that the hippocampus modulates the mnemonic strength of this reinstatement.","tags":["fMRI","episodic memory retrieval","visual perception","psychophysics","hippocampus","visual cortex","multivariate pattern analysis"],"title":"Reinstatement of associative memories in early visual cortex is signaled by the hippocampus","type":"publication"},{"authors":["__SE Bosch__","SFW Neggers","S Van der Stigchel"],"categories":null,"content":"","date":1364767200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556980323,"objectID":"49feaaf6fc0f627d241e70dd25d60849","permalink":"https://www.sanderbosch.com/publication/2013_bosch_cercor/","publishdate":"2013-04-01T00:00:00+02:00","relpermalink":"/publication/2013_bosch_cercor/","section":"publication","summary":"In order to execute a correct eye movement to a target in a search display, a saccade program toward the target element must be activated, while saccade programs toward distracting elements must be inhibited. The aim of the present study was to elucidate the role of the frontal eye fields (FEFs) in oculomotor competition. Functional magnetic resonance imaging-guided single-pulse transcranial magnetic stimulation (TMS) was administered over either the left FEF, the right FEF, or the vertex (control site) at 3 time intervals after target presentation, while subjects performed an oculomotor capture task. When TMS was applied over the FEF contralateral to the visual field where a target was presented, there was less interference of an ipsilateral distractor compared with FEF stimulation ipsilateral to the target’s visual field or TMS over vertex. Furthermore, TMS over the FEFs decreased latencies of saccades to the contralateral visual field, irrespective of whether the saccade was directed to the target or to the distractor. These findings show that single-pulse TMS over the FEFs enhances the selection of a target in the contralateral visual field and decreases saccade latencies to the contralateral visual field.","tags":["transcranial magnetic stimulation","fMRI","oculomotor capture","frontal eye fields","eye movements"],"title":"The role of the frontal eye fields in oculomotor competition: image-guided TMS enhances contralateral target selection","type":"publication"},{"authors":["IJM van der Ham","MJE van Zandvoort","T Meilinger","__SE Bosch__","N Kant","A Postma"],"categories":null,"content":"","date":1277935200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556889476,"objectID":"5fc3ba0e1fba1fca25ebc309cb8f5e54","permalink":"https://www.sanderbosch.com/publication/2010_van-der-ham_neurorep/","publishdate":"2010-07-01T00:00:00+02:00","relpermalink":"/publication/2010_van-der-ham_neurorep/","section":"publication","summary":"We present two cases (A.C. and W.J.) with navigation problems resulting from parieto-occipital right hemisphere damage. For both the cases, performance on the neuropsychological tests did not indicate specific impairments in spatial processing, despite severe subjective complaints of spatial disorientation. Various aspects of navigation were tested in a new virtual reality task, the Virtual Tübingen task. A double dissociation between spatial and temporal deficits was found; A.C. was impaired in route ordering, a temporal test, whereas W.J. was impaired in scene recognition and route continuation, which are spatial in nature. These findings offer important insights in the functional and neural architecture of navigation.","tags":["patient study","spatial processing","navigation","virtual reality"],"title":"Spatial and temporal aspects of navigation in two neurological patients","type":"publication"}]